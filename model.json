{
  "remoteClasses": [
    {
      "name": "PlayerEndpoint",
      "extends": "UriEndpoint",
      "doc": "Retrieves content from seekable sources in reliable\nmode (does not discard media information) and inject \nthem into :term:`KMS`. It\ncontains one :rom:cls:`MediaSource` for each media type detected.",
      "properties": [
        {
          "name": "useEncodedMedia",
          "doc": "use encoded instead of raw media. If the parameter is false then the\nelement uses raw media. Changing this parameter can affect stability\nseverely, as lost key frames lost will not be regenerated. Changing the media type does not\naffect to the result except in the performance (just in the case where\noriginal media and target media are the same) and in the problem with the\nkey frames. We strongly recommended not to use this parameter because\ncorrect behaviour is not guarantied.",
          "type": "boolean",
          "mutable": false,
          "defaultValue": false
        }
      ],
      "methods": [
        {
          "name": "play",
          "doc": "Starts to send data to the endpoint :rom:cls:`MediaSource`",
          "params": []
        }
      ],
      "events": [
        "EndOfStream"
      ]
    },
    {
      "name": "MediaObject",
      "doc": "Base for all objects that can be created in the media server.",
      "abstract": true,
      "properties" :[
        { "name": "mediaPipeline",
          "doc": "the pipeline to which this MediaObject belong, or the pipeline itself in a :rom:cls:`MediaPipeline`",
          "type": "MediaPipeline",
          "mutable": false
        },
        { "name": "parent",
          "doc": "the parent of this media object. The type of the parent depends on the type of the element:\n\nThe parent of a :rom:cls:`MediaPad` is its :rom:cls:`MediaElement`; the parent of a :rom:cls:`Hub` or a :rom:cls:`MediaElement` is its :rom:cls:`MediaPipeline`.\n\nA :rom:cls:`MediaPipeline` has no parent, i.e. the this property holds a null value",
          "type": "MediaObject",
          "mutable": false
        }
      ],
      "events": [
        "Error"
      ]
    },
    {
      "name": "HttpGetEndpoint",
      "extends": "HttpEndpoint",
      "doc": "An ``HttpGetEndpoint`` contains SOURCE pads for AUDIO and VIDEO, delivering media using HTML5 pseudo-streaming mechanism.\n\n   This type of endpoint provide unidirectional communications. Its :rom:cls:`MediaSink` is associated with the HTTP GET method",
      "properties": [
        {
          "name": "terminateOnEOS",
          "doc": "raise a :rom:evnt:`MediaSessionTerminated` event when the associated player raises a :rom:evnt:`EndOfStream`, and thus terminate the media session",
          "type": "boolean",
          "mutable": false,
          "defaultValue": false
        },
        {
          "name": "mediaProfile",
          "doc": "the :rom:enum:`MediaProfileSpecType` (WEBM, MP4...) for the endpoint",
          "type": "MediaProfileSpecType",
          "mutable": false,
          "defaultValue": "WEBM"
        }
      ]
    },
    {
      "name": "WebRtcEndpoint",
      "extends": "SdpEndpoint",
      "doc": "WebRtcEndpoint interface. This type of ``Endpoint`` offers media streaming using WebRTC.",
      "properties": []
    },
    {
      "name": "SessionEndpoint",
      "doc": "Session based endpoint. A session is considered to be started when the media exchange starts. On the other hand, sessions terminate when a timeout, defined by the developer, takes place after the connection is lost.",
      "abstract": true,
      "extends": "Endpoint",
      "properties": [],
      "events": [
        "MediaSessionTerminated",
        "MediaSessionStarted"
      ]
    },
    {
      "name": "Hub",
      "extends": "MediaObject",
      "doc": "A Hub is a routing :rom:cls:`MediaObject`. It connects several :rom:cls:`endpoints <Endpoint>` together",
      "properties": [],
      "abstract": true
    },
    {
      "name": "ZBarFilter",
      "extends": "Filter",
      "doc": "This filter detects :term:`QR` codes in a video feed. When a code is found, the filter raises a :rom:evnt:`CodeFound` event.",
      "properties": [],
      "events": [
        "CodeFound"
      ]
    },
    {
      "name": "Filter",
      "abstract": true,
      "extends": "MediaElement",
      "doc": "Base interface for all filters. This is a certain type of :rom:cls:`MediaElement`, that processes media injected through its :rom:cls:`MediaSink`, and delivers the outcome through its :rom:cls:`MediaSource`.",
      "properties": []
    },
    {
      "name": "Endpoint",
      "abstract": true,
      "extends": "MediaElement",
      "doc": "Base interface for all end points. An Endpoint is a :rom:cls:`MediaElement`\nthat allow :term:`KMS` to interchange media contents with external systems,\nsupporting different transport protocols and mechanisms, such as :term:`RTP`,\n:term:`WebRTC`, :term:`HTTP`, ``file:/`` URLs... An ``Endpoint`` may\ncontain both sources and sinks for different media types, to provide\nbidirectional communication.",
      "properties": []
    },
    {
      "name": "HubPort",
      "extends": "MediaElement",
      "doc": "This :rom:cls:`MediaElement` specifies a connection with a :rom:cls:`Hub`",
      "properties": [
        {
          "name": "hub",
          "doc": ":rom:cls:`Hub` to which this port belongs",
          "type": "Hub",
          "mutable": false
        }
      ]
    },
    {
      "name": "PointerDetectorAdvFilter",
      "extends": "Filter",
      "doc": "This type of :rom:cls:`Filter` detects UI pointers in a video feed.",
      "properties": [
        {
          "name": "calibrationRegion",
          "doc": "region to calibrate the filter",
          "type": "WindowParam",
          "mutable": false
        },
        {
          "name": "windows",
          "doc": "list of detection windows for the filter.",
          "type": "PointerDetectorWindowMediaParam[]",
          "mutable": true,
          "defaultValue": []
        }
      ],
      "methods": [
        {
          "name": "trackColorFromCalibrationRegion",
          "doc": "This method allows to calibrate the tracking color.\n\nThe new tracking color will be the color of the object in the colorCalibrationRegion.",
          "params": []
        }
      ],
      "events": [
        "WindowIn",
        "WindowOut"
      ]
    },
    {
      "name": "UriEndpoint",
      "abstract": true,
      "extends": "Endpoint",
      "doc": "Interface for endpoints the require a URI to work. An example of this, would be a :rom:cls:`PlayerEndpoint` whose URI property could be used to locate a file to stream through its :rom:cls:`MediaSource`",
      "properties": [
        {
          "name": "uri",
          "doc": "URI that will be used",
          "type": "String",
          "mutable": false
        }
      ],
      "methods": [
        {
          "name": "pause",
          "doc": "Pauses the feed",
          "params": []
        },
        {
          "name": "stop",
          "doc": "Stops the feed",
          "params": []
        }
      ]
    },
    {
      "name": "HttpPostEndpoint",
      "extends": "HttpEndpoint",
      "doc": "An :rom:cls:`HttpPostEndpoint` contains SINK pads for AUDIO and VIDEO, which provide access to an HTTP file upload function\n\n   This type of endpoint provide unidirectional communications. Its :rom:cls:`MediaSources <MediaSource>` are accessed through the :term:`HTTP` POST method.",
      "properties": [
        {
          "name": "useEncodedMedia",
          "doc": "configures the endpoint to use encoded media instead of raw media. If the parameter is not set then the element uses raw media. Changing this parameter could affect in a severe way to stability because key frames lost will not be generated. Changing the media type does not affect to the result except in the performance (just in the case where original media and target media are the same) and in the problem with the key frames. We strongly recommended not to use this parameter because correct behaviour is not guarantied.",
          "type": "boolean",
          "mutable": false,
          "defaultValue": false
        }
      ],
      "events": [
        "EndOfStream"
      ]
    },
    {
      "name": "RtpEndpoint",
      "extends": "SdpEndpoint",
      "doc": "Endpoint that provides bidirectional content delivery capabilities with remote networked peers through RTP protocol. An :rom:cls:`RtpEndpoint` contains paired sink and source :rom:cls:`MediaPad` for audio and video.",
      "properties": []
    },
    {
      "name": "MediaPad",
      "abstract": true,
      "extends": "MediaObject",
      "doc": "A :rom:cls:`MediaPad` is an element´s interface with the outside world. The data streams flow from the :rom:cls:`MediaSource` pad to another element's :rom:cls:`MediaSink` pad.",
      "properties": [
        {
          "name": "mediaType",
          "doc": "the type of media that this pad accepts. One of :rom:attr:`MediaType.AUDIO`, :rom:attr:`MediaType.DATA` or :rom:attr:`MediaType.VIDEO`",
          "type": "MediaType",
          "mutable": false
        },
        {
          "name": "mediaDescription",
          "doc": "description for this pad.\n\n   This method does not make a request to the media server, and is included to keep the simmetry with the rest of methods from the API.",
          "type": "String",
          "mutable": false,
          "defaultValue": ""
       }
      ],
      "methods": [
        {
          "name": "getMediaElement",
          "doc": "Obtains the parent :rom:cls:`MediaElement` that encloses this pad. Returns the value of the :rom:attr:`parent` property.",
          "params": [],
          "return": {
            "doc": "the element",
            "type": "MediaElement"
          }
        }
      ]
    },
    {
      "name": "PointerDetectorFilter",
      "extends": "Filter",
      "doc": "This type of :rom:cls:`Filter` detects pointers in a video feed.",
      "properties": [
        { "name": "windows",
          "doc": "list of detection windows for the filter to detect pointers entering or exiting the window (add, clear, remove)",
          "type": "PointerDetectorWindowMediaParam[]",
          "mutable": true
        }
      ],
      "events": [
        "WindowIn",
        "WindowOut"
      ]
    },
    {
      "name": "MediaSource",
      "abstract": true,
      "extends": "MediaPad",
      "doc": "Special type of pad, used by a media element to generate a media stream.",
      "properties": [
        {
          "name": "connectedSinks",
          "doc": ":rom:cls:`MediaSinks<MediaSink>` to which this source is connected",
          "type": "MediaSink[]",
          "mutable": false,
          "volatile": true,
          "defaultValue": []
        }
      ],
      "methods": [
        {
          "name": "connect",
          "doc": "Connects the current source with a :rom:cls:`MediaSink`",
          "params": [
            {
              "name": "sink",
              "doc": "The sink to connect this source",
              "type": "MediaSink"
            }
          ]
        }
      ]
    },
    {
      "name": "ChromaFilter",
      "extends": "Filter",
      "doc": "ChromaFilter interface. This type of :rom:cls:`Filter` makes transparent a colour\nrange in the top layer, revealing another image behind",
      "properties": [
        {
          "name": "window",
          "doc": "Window of replacement for the :rom:cls:`ChromaFilter`",
          "type": "WindowParam",
          "mutable": false
        },
        {
          "name": "backgroundImage",
          "doc": "url of image to be used to replace the detected background",
          "type": "String",
          "mutable": true,
          "defaultValue": null
        }
      ]
    },
    {
      "name": "MediaPipeline",
      "extends": "MediaObject",
      "doc": "A pipeline is a container for a collection of :rom:cls:`MediaElements<MediaElement>` and :rom:cls:`Hubs<Hub>`. It offers the methods needed to control the creation and connection of elements inside a certain pipeline.",
      "properties": []
    },
    {
      "name": "MediaSink",
      "abstract": true,
      "extends": "MediaPad",
      "doc": "Special type of pad, used by a :rom:cls:`MediaElement` to receive a media stream.",
      "properties": [
        {
          "name": "connectedSrc",
          "type": "MediaSource",
          "doc": "the :rom:cls:`MediaSource` that is connected to this sink.",
          "mutable": false,
          "volatile": true,
          "defaultValue": null
        }
      ],
      "methods": [
        {
          "name": "disconnect",
          "doc": "Disconnects the current sink from the referred :rom:cls:`MediaSource`",
          "params": [
            {
              "name": "src",
              "doc": "The source to disconnect",
              "type": "MediaSource"
            }
          ]
        }
      ]
    },
    {
      "name": "Dispatcher",
      "extends": "Hub",
      "doc": "A :rom:cls:`Hub` that allows routing between arbitrary port pairs",
      "properties": [],
      "methods": [
        {
          "name": "connect",
          "doc": "Connects each corresponding :rom:enum:`MediaType` of the given source port with the sink port.",
          "params": [
            {
              "name": "source",
              "doc": "Source port to be connected",
              "type": "HubPort"
            },
            {
              "name": "sink",
              "doc": "Sink port to be connected",
              "type": "HubPort"
            }
          ]
        }
      ]
    },
    {
      "name": "DispatcherOneToMany",
      "extends": "Hub",
      "doc": "A :rom:cls:`Hub` that sends a given source to all the connected sinks",
      "properties": [
        {
          "name": "source",
          "doc": "source to be broadcasted",
          "type": "HubPort",
          "mutable": true,
          "defaultValue": null
        }
      ]
    },
    {
      "name": "Composite",
      "extends": "Hub",
      "doc": "A :rom:cls:`Hub` that mixes the :rom:attr:`MediaType.AUDIO` stream of its connected sources and constructs a grid with the :rom:attr:`MediaType.VIDEO` streams of its connected sources into its sink",
      "properties": []
    },
    {
      "name": "JackVaderFilter",
      "extends": "Filter",
      "doc": "Filter that detects faces in a video feed. Those on the right half of the feed are overlaid with a pirate hat, and those on the left half are covered by a Darth Vader helmet. This is an example filter, intended to demonstrate how to integrate computer vision capabilities into the multimedia infrastructure.",
      "properties": []
    },
    {
      "name": "HttpEndpoint",
      "abstract": true,
      "extends": "SessionEndpoint",
      "doc": "Endpoint that enables Kurento to work as an HTTP server, allowing peer HTTP clients to access media.",
      "properties": [
        {
          "name": "url",
          "type": "String",
          "doc": "the URL associated to this endpoint",
          "mutable": false
        },
        {
          "name": "disconnectionTimeout",
          "doc": "disconnection timeout in seconds.\n\nThis is the time that an http endpoint will wait for a reconnection, in case an HTTP connection is lost.",
          "type": "int",
          "mutable": false,
          "defaultValue": 2
        }
      ]
    },
    {
      "name": "SdpEndpoint",
      "abstract": true,
      "extends": "SessionEndpoint",
      "doc": "Implements an SDP negotiation endpoint able to generate and process offers/responses and that configures resources according to negotiated Session Description",
      "properties": [
        {
          "name": "localSessionDescriptor",
          "type": "String",
          "doc": "SessionSpec offered by this NetworkConnection.\n\n.. note:: Holds the local MediaSpec, negotiated or not. If no offer has been generated yet, it has a null value. It an offer has been generated it has the offer and if an answer has been processed it holds the negotiated local SessionSpec.",
          "mutable": true,
          "defaultValue": null
        },
        {
          "name": "remoteSessionDescriptor",
          "type": "String",
          "doc": "Remote session description.\n\n.. note:: It holds the media previously agreed after a complete offer-answer exchange. If no media has been agreed yet, it holds a null value.",
          "mutable": true,
          "defaultValue": null
        }
      ],
      "methods": [
        {
          "name": "generateOffer",
          "doc": "Request a SessionSpec offer.\n\n   This can be used to initiate a connection.",
          "params": [],
          "return": {
            "doc": "The SDP offer.",
            "type": "String"
          }
        },
        {
          "name": "processOffer",
          "doc": "Request the NetworkConnection to process the given SessionSpec offer (from the remote User Agent)",
          "params": [
            {
              "name": "offer",
              "doc": "SessionSpec offer from the remote User Agent",
              "type": "String"
            }
          ],
          "return": {
            "doc": "The chosen configuration from the ones stated in the SDP offer",
            "type": "String"
          }
        },
        {
          "name": "processAnswer",
          "doc": "Request the NetworkConnection to process the given SessionSpec answer (from the remote User Agent).",
          "params": [
            {
              "name": "answer",
              "doc": "SessionSpec answer from the remote User Agent",
              "type": "String"
            }
          ],
          "return": {
            "doc": "Updated SDP offer, based on the answer received.",
            "type": "String"
          }
        }
      ]
    },
    {
      "name": "FaceOverlayFilter",
      "extends": "Filter",
      "doc": "FaceOverlayFilter interface. This type of :rom:cls:`Filter` detects faces in a video feed. The face is then overlaid with an image.",
      "properties": [
        {
          "name": "overlayedImage",
          "doc": "uri of image to be shown over each detected face",
          "type": "String",
          "mutable": true,
          "defaultValue": null
        },
        {
          "name": "offsetXPercent",
          "doc": "the offset applied to the image, from the X coordinate of the detected face upper right corner. A positive value indicates right displacement, while a negative value moves the overlaid image to the left. This offset is specified as a percentage of the face width.\n\nFor example, to cover the detected face with the overlaid image, the parameter has to be ``0.0``. Values of ``1.0`` or ``-1.0`` indicate that the image upper right corner will be at the face´s X coord, +- the face´s width.\n\n.. note::\n\n    The parameter name is misleading, the value is not a percent but a ratio",
          "type": "float",
          "mutable": true,
          "defaultValue": 0.0
        },
        {
          "name": "offsetYPercent",
          "doc": "the offset applied to the image, from the Y coordinate of the detected face upper right corner. A positive value indicates up displacement, while a negative value moves the overlaid image down. This offset is specified as a percentage of the face width.\n\nFor example, to cover the detected face with the overlaid image, the parameter has to be ``0.0``. Values of ``1.0`` or ``-1.0`` indicate that the image upper right corner will be at the face´s Y coord, +- the face´s width.\n\n.. note::\n\n    The parameter name is misleading, the value is not a percent but a ratio",
          "type": "float",
          "mutable": true,
          "defaultValue": 0.0
        },
        {
          "name": "widthPercent",
          "doc": "proportional width of the overlaid image, relative to the width of the detected face. A value of 1.0 implies that the overlaid image will have the same width as the detected face. Values greater than 1.0 are allowed, while negative values are forbidden.\n\n.. note::\n\n    The parameter name is misleading, the value is not a percent but a ratio",
          "type": "float",
          "mutable": true,
          "defaultValue": 1.0
        },
        {
          "name": "heightPercent",
          "doc": "proportional height of the overlaid image, relative to the height of the detected face. A value of 1.0 implies that the overlaid image will have the same height as the detected face. Values greater than 1.0 are allowed, while negative values are forbidden.\n\n.. note::\n\n    The parameter name is misleading, the value is not a percent but a ratio",
          "type": "float",
          "mutable": true,
          "defaultValue": 1.0
        }
      ],
      "methods": [
        {
          "name": "unsetOverlayedImage",
          "doc": "Clear the image to be shown over each detected face. Stops overlaying the faces.",
          "params": []
        },
        {
          "name": "setOverlayedImage",
          "doc": "Sets the image to use as overlay on the detected faces.",
          "params": [
            {
              "name": "uri",
              "doc": "URI where the image is located",
              "type": "String"
            },
            {
              "name": "offsetXPercent",
              "doc": "the offset applied to the image, from the X coordinate of the detected face upper right corner. A positive value indicates right displacement, while a negative value moves the overlaid image to the left. This offset is specified as a percentage of the face width.\n\nFor example, to cover the detected face with the overlaid image, the parameter has to be ``0.0``. Values of ``1.0`` or ``-1.0`` indicate that the image upper right corner will be at the face´s X coord, +- the face´s width.\n\n.. note::\n\n    The parameter name is misleading, the value is not a percent but a ratio",
              "type": "float"
            },
            {
              "name": "offsetYPercent",
              "doc": "the offset applied to the image, from the Y coordinate of the detected face upper right corner. A positive value indicates up displacement, while a negative value moves the overlaid image down. This offset is specified as a percentage of the face width.\n\nFor example, to cover the detected face with the overlaid image, the parameter has to be ``0.0``. Values of ``1.0`` or ``-1.0`` indicate that the image upper right corner will be at the face´s Y coord, +- the face´s width.\n\n.. note::\n\n    The parameter name is misleading, the value is not a percent but a ratio",
              "type": "float"
            },
            {
              "name": "widthPercent",
              "doc": "proportional width of the overlaid image, relative to the width of the detected face. A value of 1.0 implies that the overlaid image will have the same width as the detected face. Values greater than 1.0 are allowed, while negative values are forbidden.\n\n.. note::\n\n    The parameter name is misleading, the value is not a percent but a ratio",
              "type": "float"
            },
            {
              "name": "heightPercent",
              "doc": "proportional height of the overlaid image, relative to the height of the detected face. A value of 1.0 implies that the overlaid image will have the same height as the detected face. Values greater than 1.0 are allowed, while negative values are forbidden.\n\n.. note::\n\n    The parameter name is misleading, the value is not a percent but a ratio",
              "type": "float"
            }
          ]
        }
      ]
    },
    {
      "name": "PlateDetectorFilter",
      "extends": "Filter",
      "doc": "PlateDetectorFilter interface. This type of :rom:cls:`Endpoint` detects\nvehicle plates in a video feed.",
      "properties": [],
      "events": [
        "PlateDetected"
      ]
    },
    {
      "name": "RecorderEndpoint",
      "extends": "UriEndpoint",
      "doc": "Provides function to store contents in reliable mode (doesn't discard data). It contains :rom:cls:`MediaSink` pads for audio and video.",
      "properties": [
        {
          "name": "mediaProfile",
          "doc": "Either :rom:attr:`MediaProfileSpecType.WEBM` or :rom:attr:`MediaProfileSpecType.MP4` profile for recording",
          "type": "MediaProfileSpecType",
          "mutable": false,
          "defaultValue": "WEBM"
        },
        {
          "name": "stopOnEndOfStream",
          "doc": "Forces the recorder endpoint to finish processing data when an :term:`EOS` is detected in the stream",
          "type": "boolean",
          "mutable": false,
          "defaultValue": false
        }
      ],
      "methods": [
        {
          "name": "record",
          "doc": "Starts storing media received through the :rom:cls:`MediaSink` pad",
          "params": []
        }
      ]
    },
    {
      "name": "MediaElement",
      "abstract": true,
      "extends": "MediaObject",
      "doc": "Basic building blocks of the media server, that can be interconnected through the API. A :rom:cls:`MediaElement` is a module that encapsulates a specific media capability. They can be connected to create media pipelines where those capabilities are applied, in sequence, to the stream going through the pipeline.\n\n   :rom:cls:`MediaElement` objects are classified by its supported media type (audio, video, etc.) and the flow direction: :rom:cls:`MediaSource` pads are intended for media delivery while :rom:cls:`MediaSinks<MediaSink>`  behave as reception points.",
      "properties": [
        {
          "name": "mediaSrcs",
          "doc": ":rom:cls:`sources <MediaSource>` of this element",
          "type": "MediaSource[]",
          "mutable": true
        },
        {
          "name": "mediaSinks",
          "doc": ":rom:cls:`sinks <MediaSink>` of this element",
          "type": "MediaSink[]",
          "mutable": true
        }
      ],
      "methods": [
        {
          "name": "getMediaSrcs",
          "doc": "Get the media sources of the given type and description",
          "params": [
            {
              "name": "mediaType",
              "doc": "One of :rom:attr:`MediaType.AUDIO`, :rom:attr:`MediaType.VIDEO` or :rom:attr:`MediaType.DATA`",
              "type": "MediaType",
              "optional": true
            },
            {
              "name": "description",
              "doc": "A textual description of the media source. Currently not used, aimed mainly for :rom:attr:`MediaType.DATA` sources",
              "type": "String",
              "optional": true
            }
          ],
          "return": {
            "doc": "A list of sources. The list will be empty if no sources are found.",
            "type": "MediaSource[]"
          }
        },
        {
          "name": "getMediaSinks",
          "doc": "A list of sinks of the given :rom:ref:`MediaType` and description. The list will be empty if no sinks are found.",
          "params": [
            {
              "name": "mediaType",
              "doc": "One of :rom:attr:`MediaType.AUDIO`, :rom:attr:`MediaType.VIDEO` or :rom:attr:`MediaType.DATA`",
              "type": "MediaType",
              "optional": true
            },
            {
              "name": "description",
              "doc": "A textual description of the media source. Currently not used, aimed mainly for :rom:attr:`MediaType.DATA` sources",
              "type": "String",
              "optional": true
            }
          ],
          "return": {
            "doc": "A list of sinks. The list will be empty if no sinks are found.",
            "type": "MediaSink[]"
          }
        },
        {
          "name": "connect",
          "doc": "Connects every :rom:cls:`MediaSource` of this element belonging to the specified :rom:enum:`MediaType` to the corresponding :rom:cls:`MediaSink` of the target :rom:cls:`MediaElement`. This method will throw an exception if any of the following occur:\n\n   ..\n\n   * The number of sources for the specified :rom:enum:`MediaType` in this element is different than the number of sinks on the target element.\n   * There are duplicate mediaDescriptions on this' element sources for the specified :rom:enum:`MediaType`.\n   * There are duplicate mediaDescriptions on target's element sinks for the specified :rom:enum:`MediaType`.\n   * Target sinks' media descriptions are different form this sources' media descriptions for the specified :rom:enum:`MediaType`\n\nThis method is not transactional. In case of exception some of this element sources may be connected with target sinks.",
          "params": [
            {
              "name": "sink",
              "doc": "the target :rom:cls:`MediaElement`  from which :rom:cls:`MediaSink` will be obtained",
              "type": "MediaElement"
            },
            {
              "name": "mediaType",
              "doc": "the :rom:enum:`MediaType` of the pads that will be connected",
              "type": "MediaType",
              "optional": true
            },
            {
              "name": "mediaDescription",
              "doc": "A textual description of the media source. Currently not used, aimed mainly for :rom:attr:`MediaType.DATA` sources",
              "type": "String",
              "optional": true
            }
          ]
        }
      ]
    },
    {
      "name": "GStreamerFilter",
      "extends": "Filter",
      "doc": "This is a generic filter interface, that creates GStreamer filters in the media server.",
      "properties": [
        {
          "name": "command",
          "doc": "command that will be used to instantiate the filter, same syntax as in `gst-launch <http://rpm.pbone.net/index.php3/stat/45/idpl/19531544/numer/1/nazwa/gst-launch-1.0>`__",
          "type": "String",
          "mutable": false
        }
      ]
    },
    {
      "name": "CrowdDetectorFilter",
      "doc": "Filter that detects people agglomeration in video streams",
      "extends": "Filter",
      "properties": [
        {
          "name": "rois",
          "doc": "Regions of interest for the filter",
          "type": "RegionOfInterest[]",
          "mutable": false
        }
      ],
      "events": [
        "CrowdDetectorFluidity",
        "CrowdDetectorOccupancy",
        "CrowdDetectorDirection"
      ]
    }
  ],
  "complexTypes": [
    {
      "typeFormat": "ENUM",
      "values": [
        "WEBM",
        "MP4"
      ],
      "name": "MediaProfileSpecType",
      "doc": "Media Profile.\n\nCurrently WEBM and MP4 are supported."
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "AUDIO",
        "DATA",
        "VIDEO"
      ],
      "name": "MediaType",
      "doc": "Type of media stream to be exchanged.\nCan take the values AUDIO, DATA or VIDEO."
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "id",
          "doc": "id of the window for pointer detection",
          "type": "String"
        },
        {
          "name": "height",
          "doc": "height in pixels",
          "type": "int"
        },
        {
          "name": "width",
          "doc": "width in pixels",
          "type": "int"
        },
        {
          "name": "upperRightX",
          "doc": "X coordinate in pixels of the upper left corner",
          "type": "int"
        },
        {
          "name": "upperRightY",
          "doc": "Y coordinate in pixels of the upper left corner",
          "type": "int"
        },
        {
          "name": "activeImage",
          "doc": "uri of the image to be used when the pointer is inside the window",
          "type": "String",
          "optional": true
        },
        {
          "name": "imageTransparency",
          "doc": "transparency ratio of the image",
          "type": "float",
          "optional": true
        },
        {
          "name": "image",
          "doc": "uri of the image to be used for the window.\n\nIf :rom:attr:`activeImage` has been set, it will only be shown when the pointer is outside of the window.",
          "type": "String",
          "optional": true
        }
      ],
      "name": "PointerDetectorWindowMediaParam",
      "doc": "Data structure for UI Pointer detection in video streams.\n\nAll the coordinates are in pixels. X is horizontal, Y is vertical, running from the top of the window. Thus, 0,0 corresponds to the topleft corner."
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "topRightCornerX",
          "doc": "X coordinate of the left upper point of the window",
          "type": "int"
        },
        {
          "name": "topRightCornerY",
          "doc": "Y coordinate of the left upper point of the window",
          "type": "int"
        },
        {
          "name": "width",
          "doc": "width in pixels of the window",
          "type": "int"
        },
        {
          "name": "height",
          "doc": "height in pixels of the window",
          "type": "int"
        }
      ],
      "name": "WindowParam",
      "doc": "Parameter representing a window in a video stream.\nIt is used in command and constructors for media elements.\n\nAll units are in pixels, X runs from left to right, Y from top to bottom."
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "occupancyLevelMin",
          "doc": "minimun occupancy percentage in the ROI to send occupancy events",
          "type": "int",
          "optional": true,
          "defaultValue": 10
        },
        {
          "name": "occupancyLevelMed",
          "doc": "send occupancy level = 1 if the occupancy percentage is between occupancy_level_min and this level",
          "type": "int",
          "optional": true,
          "defaultValue": 35
        },
        {
          "name": "occupancyLevelMax",
          "doc": "send occupancy level = 2 if the occupancy percentage is between occupancy_level_med and this level,\nand send occupancy level = 3 if the occupancy percentage is between this level and 100",
          "type": "int",
          "optional": true,
          "defaultValue": 65
        },
        {
          "name": "occupancyNumFramesToEvent",
          "doc": "number of consecutive frames that a new occupancy level has to be detected to recognize it as a occupancy level change.\nA new occupancy event will be send",
          "type": "int",
          "optional": true,
          "defaultValue": 5
        },
        {
          "name": "fluidityLevelMin",
          "doc": "minimun fluidity percentage in the ROI to send fluidity events",
          "type": "int",
          "optional": true,
          "defaultValue": 10
        },
        {
          "name": "fluidityLevelMed",
          "doc": "send fluidity level = 1 if the fluidity percentage is between fluidity_level_min and this level",
          "type": "int",
          "optional": true,
          "defaultValue": 35
        },
        {
          "name": "fluidityLevelMax",
          "doc": "send fluidity level = 2 if the fluidity percentage is between fluidity_level_med and this level,\n and send fluidity level = 3 if the fluidity percentage is between this level and 100",
          "type": "int",
          "optional": true,
          "defaultValue": 65
        },
        {
          "name": "fluidityNumFramesToEvent",
          "doc": "number of consecutive frames that a new fluidity level has to be detected to recognize it as a fluidity level change.\n A new fluidity event will be send",
          "type": "int",
          "optional": true,
          "defaultValue": 5
        },
        {
          "name": "sendOpticalFlowEvent",
          "doc": "Enable/disable the movement direction detection into the ROI",
          "type": "boolean",
          "optional": true,
          "defaultValue": false
        },
        {
          "name": "opticalFlowNumFramesToEvent",
          "doc": "number of consecutive frames that a new direction of movement has to be detected to recognize a new movement direction. \n A new direction event will be send",
          "type": "int",
          "optional": true,
          "defaultValue": 3
        },
        {
          "name": "opticalFlowNumFramesToReset",
          "doc": "number of consecutive frames in order to reset the counter of repeated directions",
          "type": "int",
          "optional": true,
          "defaultValue": 3
        },
        {
          "name": "opticalFlowAngleOffset",
          "doc": "Direction of the movement. The angle could have four different values: \n left (0), up (90), right (180) and down (270). This cartesian axis could be rotated adding an angle offset",
          "type": "int",
          "optional": true,
          "defaultValue": 0
        }
      ],
      "name": "RegionOfInterestConfig",
      "doc": "data structure for configuration of CrowdDetector regions of interest"
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "points",
          "doc": "list of points delimiting the region of interest",
          "type": "Point[]"
        },
        {
          "name": "regionOfInterestConfig",
          "doc": "data structure for configuration of CrowdDetector regions of interest",
          "type": "RegionOfInterestConfig"
        },
        {
          "name": "id",
          "doc": "identifier of the region of interest",
          "type": "String"
        }
      ],
      "name": "RegionOfInterest",
      "doc": "Region of interest for some events in a video processing filter"
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "x",
          "doc": "X coordinate in pixels of a point in the screen",
          "type": "int"
        },
        {
          "name": "y",
          "doc": "Y coordinate in pixels of a point in the screen",
          "type": "int"
        }
      ],
      "name": "Point",
      "doc": "Point in a physical screen, coordinates are in pixels with X left to right and Y top to down."
    }
  ],
  "events": [
    {
      "properties": [
        {
          "name": "plate",
          "doc": "Plate identification that was detected by the filter",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "PlateDetected",
      "doc": "Event raised by a :rom:cls:`PlateDetectorFilter` when a plate is found in the data streamed."
    },
    {
      "properties": [],
      "extends": "Media",
      "name": "EndOfStream",
      "doc": "Event raised when the stream that the element sends out is finished.\nAn element receiving this event will generally just process any buffered\ndata, and then forward the event further downstream."
    },
    {
      "properties": [
        {
          "name": "codeType",
          "doc": "type of :term:`QR` code found",
          "type": "String"
        },
        {
          "name": "value",
          "doc": "value contained in the :term:`QR` code",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "CodeFound",
      "doc": "Event raised by a :rom:cls:`ZBarFilter` when a code is found in the data being streamed."
    },
    {
      "properties": [
        {
          "name": "object",
          "doc": ":rom:cls:`MediaObject` where the error originated",
          "type": "MediaObject"
        },
        {
          "name": "description",
          "doc": "Textual description of the error",
          "type": "String"
        },
        {
          "name": "errorCode",
          "doc": "Server side integer error code",
          "type": "int"
        },
        {
          "name": "type",
          "doc": "Integer code as a String",
          "type": "String"
        }
      ],
      "name": "Error",
      "doc": "An error related to the MediaObject has occurred"
    },
    {
      "properties": [],
      "extends": "Media",
      "name": "MediaSessionTerminated",
      "doc": "Event raised when a session is terminated. This event has no data."
    },
    {
      "properties": [
        {
          "name": "windowId",
          "doc": "Opaque String indicating the id of the window entered",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "WindowIn",
      "doc": "Event generated when an object enters a window."
    },
    {
      "properties": [],
      "extends": "Media",
      "name": "MediaSessionStarted",
      "doc": "Event raised when a session starts. This event has no data."
    },
    {
      "properties": [
        {
          "name": "windowId",
          "doc": "Opaque String indicating the id of the window entered",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "WindowOut",
      "doc": "Event generated when an object exits a window."
    },
    {
      "properties": [
        {
          "name": "source",
          "doc": "Object that raised the event",
          "type": "MediaObject"
        },
        {
          "name": "type",
          "doc": "Type of event that was raised",
          "type": "String"
        }
      ],
      "name": "Media",
      "doc": "Base for all events raised by elements in the Kurento media server."
    },
    {
      "properties": [
        {
          "name": "fluidityPercentage",
          "doc": "Percentage of fluidity in the ROI",
          "type": "float"
        },
        {
          "name": "fluidityLevel",
          "doc": "Level of fluidity in the ROI",
          "type": "int"
        },
        {
          "name": "roiID",
          "doc": "Opaque String indicating the id of the involved ROI",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "CrowdDetectorFluidity",
      "doc": "Event raise when a level of fluidity is detected in a ROI"
    },
    {
      "properties": [
        {
          "name": "occupancyPercentage",
          "doc": "Percentage of occupancy in the ROI",
          "type": "float"
        },
        {
          "name": "occupancyLevel",
          "doc": "Level of occupancy in the ROI",
          "type": "int"
        },
        {
          "name": "roiID",
          "doc": "Opaque String indicating the id of the involved ROI",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "CrowdDetectorOccupancy",
      "doc": "Event raise when a level of occupancy is detected in a ROI"
    },
    {
      "properties": [
        {
          "name": "directionAngle",
          "doc": "Direction angle of the detected movement in the ROI",
          "type": "float"
        },
        {
          "name": "roiID",
          "doc": "Opaque String indicating the id of the involved ROI",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "CrowdDetectorDirection",
      "doc": "Event raise when a movement direction is detected in a ROI"
    }
  ]
}
